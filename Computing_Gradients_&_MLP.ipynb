{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_NENgiuvY47v",
        "outputId": "6f9031c1-d136-4a5c-b947-a0b963c0815e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(tensor([-0.0898]),) (tensor([-0.1797]),) (tensor([-0.0817]),)\n"
          ]
        }
      ],
      "source": [
        "import torch.nn.functional as F # For binary cross entropy\n",
        "from torch.autograd import grad\n",
        "import torch\n",
        "\n",
        "x1 = torch.tensor([1.1], requires_grad = True)\n",
        "w1 = torch.tensor([2.2], requires_grad=True)\n",
        "b = torch.tensor([0.0], requires_grad = True)\n",
        "y = torch.tensor([1.0])\n",
        "\n",
        "z = x1 * w1 + b\n",
        "\n",
        "a = torch.sigmoid(z)\n",
        "loss = F.binary_cross_entropy(a, y)\n",
        "\n",
        "grad_l_w1 = grad(loss, w1, retain_graph=True)\n",
        "grad_l_x1 = grad(loss, x1, retain_graph=True)\n",
        "grad_l_b = grad(loss, b, retain_graph=True)\n",
        "\n",
        "print(grad_l_w1, grad_l_x1, grad_l_b)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class NeuralNetwork(torch.nn.Module):\n",
        "  def __init__(self, num_inputs, num_outputs):\n",
        "    super().__init__()\n",
        "\n",
        "    self.layers = torch.nn.Sequential(\n",
        "        # 1st Hidden Layer\n",
        "        torch.nn.Linear(num_inputs, 30),\n",
        "        torch.nn.ReLU(),\n",
        "\n",
        "        # 2nd Hidden Layer\n",
        "        torch.nn.Linear(30, 20),\n",
        "        torch.nn.ReLU(),\n",
        "\n",
        "        # Output Layer\n",
        "        torch.nn.Linear(20, num_outputs)\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    logits = self.layers(x)\n",
        "    return logits\n",
        "\n",
        "model = NeuralNetwork(50, 3)"
      ],
      "metadata": {
        "id": "2DR1tIL7AAUx"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fhClq-yUBNKE",
        "outputId": "feec34a7-4f83-4934-a8b6-9bcce616b2ee"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NeuralNetwork(\n",
            "  (layers): Sequential(\n",
            "    (0): Linear(in_features=50, out_features=30, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Linear(in_features=30, out_features=20, bias=True)\n",
            "    (3): ReLU()\n",
            "    (4): Linear(in_features=20, out_features=3, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_params = sum(p.numel() for p in model.parameters() if p.requires_grad == True)\n",
        "\n",
        "print(f\"Total number of parameters in the model are: {num_params}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_lvAkyQ9BRiy",
        "outputId": "4d614513-2c59-41fc-a7ec-6b8d1488e1f7"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total number of parameters in the model are: 2213\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(model.layers[0].weight)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CvBjLCFJBmUW",
        "outputId": "94960bfc-3e36-4c02-e21d-db49837b35d9"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parameter containing:\n",
            "tensor([[ 0.0714,  0.0363, -0.0687,  ..., -0.0429, -0.0765,  0.0044],\n",
            "        [ 0.1295,  0.0685, -0.0509,  ..., -0.0074,  0.1233,  0.0608],\n",
            "        [-0.0617,  0.1156, -0.0155,  ..., -0.1365,  0.1253, -0.0089],\n",
            "        ...,\n",
            "        [ 0.0893,  0.1142,  0.0590,  ..., -0.0798,  0.0860,  0.0544],\n",
            "        [-0.0216,  0.0721, -0.1077,  ..., -0.0061, -0.0851,  0.0069],\n",
            "        [ 0.0023,  0.0969,  0.0873,  ..., -0.0815, -0.1350, -0.0048]],\n",
            "       requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(model.layers[0].weight.shape) # You can do this for all layers. Check the significance for this again"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bBxG0_RMCwjU",
        "outputId": "c3e62198-40a4-4b8f-d833-95476c655bfe"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([30, 50])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(model.layers[0].bias)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-fh74u36DCIX",
        "outputId": "0f5dffd5-7c00-4337-a6a4-417f3367a465"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parameter containing:\n",
            "tensor([-0.0010, -0.0828, -0.0295, -0.1003, -0.0781, -0.0969,  0.1121,  0.1172,\n",
            "        -0.0983,  0.1357,  0.0099,  0.0482, -0.0004,  0.0936, -0.1108,  0.0384,\n",
            "         0.1132,  0.0696,  0.0870,  0.0987, -0.0625, -0.0950,  0.1193, -0.0808,\n",
            "         0.0698,  0.0223,  0.0603,  0.0678, -0.1373, -0.1292],\n",
            "       requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# While the weights are randomly assigned and are very small numbers we would want to have reproduicble numbers\n",
        "# We can use manual_Seed for that\n",
        "\n",
        "torch.manual_seed(123)\n",
        "\n",
        "model = NeuralNetwork(50, 3)\n",
        "\n",
        "print(model.layers[0].weight)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1JaF4CTWDGow",
        "outputId": "a7db4a94-db09-4ca9-87c7-cd8bb7878636"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parameter containing:\n",
            "tensor([[-0.0577,  0.0047, -0.0702,  ...,  0.0222,  0.1260,  0.0865],\n",
            "        [ 0.0502,  0.0307,  0.0333,  ...,  0.0951,  0.1134, -0.0297],\n",
            "        [ 0.1077, -0.1108,  0.0122,  ...,  0.0108, -0.1049, -0.1063],\n",
            "        ...,\n",
            "        [-0.0787,  0.1259,  0.0803,  ...,  0.1218,  0.1303, -0.1351],\n",
            "        [ 0.1359,  0.0175, -0.0673,  ...,  0.0674,  0.0676,  0.1058],\n",
            "        [ 0.0790,  0.1343, -0.0293,  ...,  0.0344, -0.0971, -0.0509]],\n",
            "       requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# During inference, we do not need the grad module since we're just inferring it\n",
        "# So it is a good practice to set it to no_grad() which can be efficient and save us some memory.\n",
        "\n",
        "X = torch.rand((1, 50))\n",
        "with torch.no_grad():\n",
        "  output = model(X)\n",
        "\n",
        "print(X)\n",
        "print(output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JQcrwTY6DUVL",
        "outputId": "096c2796-0437-4a6b-fb21-1b4978faa533"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.5131, 0.6978, 0.4537, 0.9035, 0.5088, 0.7786, 0.9455, 0.6622, 0.5138,\n",
            "         0.4649, 0.0926, 0.1094, 0.6668, 0.5465, 0.6295, 0.0483, 0.7799, 0.4483,\n",
            "         0.6947, 0.2243, 0.6045, 0.7574, 0.1262, 0.5446, 0.3269, 0.9105, 0.3953,\n",
            "         0.2075, 0.1796, 0.4544, 0.7271, 0.6692, 0.9545, 0.8872, 0.5824, 0.6379,\n",
            "         0.2836, 0.6754, 0.8838, 0.4898, 0.5963, 0.0890, 0.7804, 0.9223, 0.9605,\n",
            "         0.7099, 0.3075, 0.5226, 0.2881, 0.2615]])\n",
            "tensor([[-0.1712,  0.0876, -0.1625]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "  output = torch.softmax(model(X), dim=1)\n",
        "\n",
        "print(output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aanv-x5nELnk",
        "outputId": "d0d2ab6f-748c-4f66-b48e-bedc44aedfac"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.3026, 0.3921, 0.3053]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class NeuralNetwork(torch.nn.Module):\n",
        "  def __init__(self, input_size, output_size):\n",
        "    super().__init__()\n",
        "\n",
        "    self.layers = torch.nn.Sequential(\n",
        "        # 1st Layer\n",
        "        torch.nn.Linear(input_size, 30),\n",
        "        torch.nn.ReLU(),\n",
        "\n",
        "        # 2nd Hidden Layer\n",
        "        torch.nn.Linear(30, 20),\n",
        "        torch.nn.ReLU(),\n",
        "\n",
        "        # 3rd Hidden Layer\n",
        "        torch.nn.Linear(20, 10),\n",
        "        torch.nn.ReLU(),\n",
        "\n",
        "        # Output Layer\n",
        "        torch.nn.Linear(10, output_size)\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    logits = self.layers(x)\n",
        "    return logits\n",
        "\n",
        "\n",
        "model = NeuralNetwork(50, 3)\n",
        "\n",
        "print(model.layers)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ge-sK_ElEwJB",
        "outputId": "89a4e55e-6c81-4a10-8133-84764e951d46"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sequential(\n",
            "  (0): Linear(in_features=50, out_features=30, bias=True)\n",
            "  (1): ReLU()\n",
            "  (2): Linear(in_features=30, out_features=20, bias=True)\n",
            "  (3): ReLU()\n",
            "  (4): Linear(in_features=20, out_features=10, bias=True)\n",
            "  (5): ReLU()\n",
            "  (6): Linear(in_features=10, out_features=3, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Model bias\n",
        "\n",
        "print(model.layers[2].bias)\n",
        "print(model.layers[2].weight)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NolYQd92FsNU",
        "outputId": "c0e2c033-a23f-4deb-b5eb-89e30db47e1b"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parameter containing:\n",
            "tensor([ 0.1568, -0.0106, -0.1436, -0.0494,  0.0016, -0.1353,  0.0561, -0.0634,\n",
            "         0.0907,  0.1818,  0.0049,  0.0597,  0.1344,  0.1318, -0.0168, -0.0886,\n",
            "         0.1197,  0.1229,  0.0204,  0.0334], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([[ 1.1081e-01,  7.2104e-02,  1.2603e-01,  6.0945e-02,  1.4608e-01,\n",
            "          1.1479e-01, -6.7819e-02,  1.1978e-01, -1.7576e-01,  3.9393e-02,\n",
            "          1.2595e-01,  1.4288e-01,  9.5834e-02,  1.1678e-01,  1.6803e-01,\n",
            "         -1.1938e-01,  1.5281e-01, -6.3345e-02, -1.5574e-01,  4.1657e-02,\n",
            "          3.7720e-02, -2.3873e-02,  4.5442e-02,  1.4656e-01,  6.4622e-02,\n",
            "         -7.6131e-02, -1.6842e-01, -8.2066e-02,  3.8972e-02,  2.2720e-02],\n",
            "        [-7.3953e-02,  1.5360e-01,  8.8083e-02,  5.6917e-02, -5.0214e-02,\n",
            "          1.6878e-01,  2.5733e-02,  1.7308e-01,  4.9521e-02, -3.6096e-02,\n",
            "         -1.5461e-01,  3.8970e-02,  2.9243e-02, -1.6099e-01,  6.7480e-02,\n",
            "          9.0143e-02,  1.4435e-01, -1.0338e-01,  1.1309e-01, -1.6003e-01,\n",
            "          6.3329e-03,  1.2893e-01, -7.7787e-02,  4.0791e-02,  3.1601e-02,\n",
            "         -1.1624e-01, -6.9051e-02,  9.2450e-02,  1.2192e-02,  1.5367e-01],\n",
            "        [ 5.0576e-02, -1.6616e-01,  1.5064e-01,  2.7834e-02, -1.1075e-01,\n",
            "          1.2715e-01,  1.3876e-01, -1.7109e-01, -1.5924e-02, -8.3277e-02,\n",
            "         -9.5293e-03,  7.2129e-02,  1.2616e-01,  1.5963e-01, -1.3222e-01,\n",
            "          6.8773e-02,  2.5878e-02,  5.4247e-02,  2.9129e-02, -1.3301e-02,\n",
            "          1.7871e-02,  1.2108e-01, -1.5621e-01, -3.6874e-02, -6.0231e-02,\n",
            "          1.3461e-01, -5.9893e-02, -1.4800e-02, -7.7146e-02, -1.7115e-01],\n",
            "        [-5.4838e-03,  1.6977e-01, -2.3351e-02,  9.4062e-02, -2.5597e-02,\n",
            "          5.3258e-02, -1.2742e-01,  1.8150e-01,  1.5961e-01, -1.2279e-01,\n",
            "         -1.6728e-01, -1.5285e-01, -1.5838e-01,  1.6123e-01, -3.2656e-02,\n",
            "          1.0096e-01,  1.2818e-01,  1.1462e-01,  1.2650e-01,  1.8137e-01,\n",
            "         -6.8310e-02,  1.6443e-01,  6.6819e-02,  1.6306e-01,  1.3964e-02,\n",
            "          1.7695e-03, -1.8082e-01, -1.7507e-01, -1.4204e-01,  7.3792e-02],\n",
            "        [-1.5254e-02,  1.0402e-01,  1.2025e-01,  8.0387e-02,  6.5052e-02,\n",
            "         -3.7790e-02, -7.3228e-02,  1.7439e-01,  5.0833e-02, -1.0379e-01,\n",
            "          1.1597e-02,  2.2326e-03,  2.7185e-02,  1.2140e-01,  7.0492e-02,\n",
            "          1.3457e-01,  1.0990e-01,  1.4872e-01, -1.9572e-02,  1.8161e-01,\n",
            "          9.5131e-02, -1.3446e-01, -2.7394e-03, -1.3284e-01, -6.7865e-02,\n",
            "          6.7965e-02, -1.6680e-01, -1.8196e-01,  1.2171e-01, -6.3751e-02],\n",
            "        [-1.3676e-01,  8.3278e-02, -1.4957e-01,  1.5816e-01,  1.6943e-01,\n",
            "         -9.3141e-02, -8.4465e-02, -2.1097e-02,  1.3750e-01, -1.1243e-01,\n",
            "         -7.1629e-02,  5.8332e-02,  1.7735e-01, -1.1688e-01, -1.4689e-01,\n",
            "         -1.5941e-01,  1.5016e-01, -1.1817e-01, -9.4598e-02,  8.3694e-02,\n",
            "         -6.0802e-02,  1.3186e-01, -1.5449e-01, -1.2832e-01,  1.5762e-01,\n",
            "         -6.5539e-02,  1.6553e-01,  9.1615e-02,  1.7220e-02, -1.1589e-01],\n",
            "        [ 1.5978e-01, -4.5475e-02, -1.2850e-01,  3.3974e-05, -1.3901e-01,\n",
            "         -3.5763e-02, -8.1066e-02, -5.4564e-02, -6.2878e-02,  1.4951e-01,\n",
            "          1.1640e-01, -6.3738e-02,  9.4361e-02,  1.5328e-01, -1.4502e-01,\n",
            "          3.6961e-02, -1.0299e-01,  4.1200e-02,  1.1042e-01,  3.4849e-02,\n",
            "          1.3241e-01, -1.4211e-02, -3.9966e-02,  1.6239e-01, -6.0130e-02,\n",
            "          1.4758e-01,  1.1889e-01, -1.5116e-01,  1.5494e-01,  2.4740e-02],\n",
            "        [-5.5741e-02, -1.1429e-01,  7.3608e-02,  1.3173e-03,  1.3713e-01,\n",
            "         -6.3559e-02,  1.0086e-01,  2.1022e-02, -1.3258e-01, -1.7476e-01,\n",
            "         -1.1783e-01, -1.2005e-01,  1.1357e-01, -8.9281e-02, -9.2076e-03,\n",
            "         -4.4392e-02,  1.4981e-01,  1.3102e-01,  8.8379e-02, -8.4763e-02,\n",
            "         -1.4238e-01,  1.7651e-01, -1.5442e-01,  8.4599e-04, -6.0232e-02,\n",
            "          5.9608e-02, -1.3116e-01, -1.3459e-01,  1.7754e-01,  9.2274e-02],\n",
            "        [ 1.7790e-01, -5.6767e-02,  1.2572e-01, -3.5396e-02, -1.3213e-01,\n",
            "         -1.6402e-01,  1.8087e-01,  8.1675e-02, -2.0520e-02, -1.1958e-01,\n",
            "          4.3852e-02,  6.3490e-02, -1.4054e-01, -6.5713e-02,  1.2638e-01,\n",
            "         -3.0877e-02, -4.2648e-02,  4.1349e-02,  8.6706e-02,  4.9134e-02,\n",
            "          5.1594e-02, -2.2354e-02,  1.2310e-01,  9.6753e-03,  7.5324e-02,\n",
            "         -8.8509e-02, -1.5503e-01, -1.3456e-01, -5.9573e-02, -7.1354e-02],\n",
            "        [-1.0556e-01,  1.0392e-01,  1.0281e-01,  1.5215e-01, -3.0331e-03,\n",
            "          6.5109e-02, -8.4326e-02, -1.5899e-01, -1.9091e-02,  9.4142e-02,\n",
            "         -5.2100e-02,  9.7143e-02, -3.1174e-02, -1.6033e-01,  6.6533e-02,\n",
            "          1.3754e-01,  9.0854e-03,  1.2334e-02,  7.3976e-02,  2.9876e-02,\n",
            "          8.2230e-02,  8.5258e-02,  5.2484e-02,  2.4038e-03, -1.3124e-01,\n",
            "         -8.4226e-02, -1.6810e-01, -1.3430e-01, -1.4833e-01,  1.1472e-01],\n",
            "        [-2.0531e-02, -7.5880e-02,  1.6792e-01,  6.1697e-02, -1.2274e-01,\n",
            "          4.0917e-02, -3.3181e-02, -8.6554e-02,  1.6556e-01, -6.0433e-02,\n",
            "          1.3206e-01,  6.8668e-02,  1.3516e-01, -6.5702e-02,  1.0732e-01,\n",
            "         -5.7889e-02,  1.7875e-01, -1.0066e-01, -1.7684e-01,  1.6470e-01,\n",
            "          1.7196e-01,  5.0798e-02,  1.7540e-02,  1.0456e-01,  4.5898e-02,\n",
            "          2.0241e-03, -1.7852e-01,  6.1235e-02, -2.7563e-02, -1.0516e-02],\n",
            "        [-1.6626e-01,  6.2269e-02,  1.0488e-01,  7.5625e-03, -1.9930e-02,\n",
            "          7.5938e-02, -1.2050e-01,  1.2942e-01,  2.7974e-02,  8.6224e-02,\n",
            "          2.8986e-02,  1.3211e-01,  4.0375e-02,  3.9751e-02,  8.0959e-02,\n",
            "          1.7224e-01,  1.5748e-01, -6.0776e-03, -7.6815e-02,  8.0494e-02,\n",
            "          1.7796e-01, -1.8096e-01,  4.0441e-02,  9.1462e-02,  9.3217e-02,\n",
            "          1.4716e-01,  6.9851e-02, -1.7768e-01,  1.4438e-01,  1.6251e-02],\n",
            "        [ 1.5575e-01,  9.0887e-02, -1.5532e-01, -7.6803e-02,  1.3903e-01,\n",
            "          1.4128e-01,  4.0615e-02, -9.0901e-02,  5.9156e-02,  8.3840e-02,\n",
            "         -1.7027e-01,  6.1495e-02,  9.6456e-02, -1.1935e-01, -8.9603e-02,\n",
            "          4.1974e-02,  1.4261e-01, -1.7655e-01, -1.3896e-01, -3.6007e-02,\n",
            "         -1.3525e-01, -3.0160e-02, -1.1584e-01,  1.4043e-01,  7.5922e-02,\n",
            "          1.7093e-01,  1.2735e-01, -1.7710e-02,  8.2937e-02,  1.8241e-01],\n",
            "        [-6.3866e-02, -1.3128e-01, -8.9532e-02,  1.1085e-01,  4.2730e-02,\n",
            "         -1.2579e-01, -5.4799e-02,  1.3159e-02,  1.5781e-01,  9.6925e-02,\n",
            "          9.9898e-03, -4.2156e-02,  3.4795e-02, -1.6102e-01, -7.4455e-02,\n",
            "         -1.7551e-01,  5.2481e-02,  8.4328e-02, -5.8315e-02,  4.4054e-02,\n",
            "          5.8492e-02,  2.5769e-02,  1.4541e-01, -1.3888e-01, -1.3846e-01,\n",
            "          1.4068e-02,  1.5552e-01,  7.7040e-03, -6.8675e-02, -1.7247e-01],\n",
            "        [ 1.2645e-01, -8.1853e-02, -4.4975e-02, -1.3568e-01,  1.7055e-03,\n",
            "          1.6110e-01, -9.8838e-02, -1.2162e-01,  6.0318e-02,  1.3057e-01,\n",
            "          5.3152e-02, -8.0036e-02, -8.1941e-02,  6.4223e-02, -1.3589e-01,\n",
            "         -6.4435e-02, -4.0844e-02, -1.1914e-01,  1.7588e-01, -2.5476e-02,\n",
            "          1.3069e-01, -2.0547e-02, -1.1326e-01, -8.7905e-02, -9.8194e-02,\n",
            "          1.1278e-01, -7.6943e-02, -3.0933e-02,  9.8239e-02, -1.3718e-01],\n",
            "        [-5.2400e-02,  4.3346e-02,  7.4895e-02,  9.3924e-02,  3.8820e-02,\n",
            "          9.5391e-02,  6.7626e-02,  7.5117e-02, -1.1634e-03, -4.8054e-03,\n",
            "         -1.1822e-01,  3.6529e-02, -1.0771e-01,  5.0680e-02,  2.0584e-02,\n",
            "         -1.3419e-01, -1.2184e-01,  9.1674e-02, -6.4918e-02,  5.3100e-02,\n",
            "          1.2908e-01,  1.3310e-01,  2.8869e-02, -4.3317e-02,  5.3862e-02,\n",
            "         -1.3058e-01, -5.0355e-02,  9.9573e-02,  8.8189e-03,  1.8045e-01],\n",
            "        [-5.1037e-02,  3.2607e-02, -8.5911e-02, -6.7757e-02,  1.4374e-03,\n",
            "          7.3381e-02,  8.1857e-02, -9.3532e-02,  1.3776e-01,  1.6614e-01,\n",
            "         -2.2284e-02, -3.7121e-02, -1.6349e-01, -7.5891e-04, -5.0534e-03,\n",
            "         -1.0776e-01,  4.2211e-02, -1.7124e-01, -3.8676e-02, -3.0544e-02,\n",
            "          5.1208e-02, -1.7957e-01, -8.6020e-02, -1.6107e-01, -1.5537e-01,\n",
            "          1.4102e-02, -5.5911e-02, -1.1325e-01, -1.5739e-01, -1.6068e-02],\n",
            "        [ 8.5505e-02, -1.1197e-01, -9.5865e-02, -4.1538e-02, -1.3420e-01,\n",
            "          4.4046e-02, -7.7361e-02, -1.6160e-01, -3.3086e-02, -3.6281e-02,\n",
            "         -6.0564e-02,  1.8058e-01, -1.4029e-01, -5.8565e-02, -6.6769e-02,\n",
            "         -1.1732e-01, -3.8484e-03,  1.7011e-01, -3.8827e-02,  1.6961e-01,\n",
            "          8.5901e-02,  3.2123e-03,  1.3498e-01,  1.6727e-01, -5.3372e-02,\n",
            "          2.3771e-02, -1.6430e-01, -1.1257e-01, -6.5856e-02, -1.1892e-01],\n",
            "        [-8.7513e-02, -7.0747e-02, -1.4815e-01, -1.6449e-01,  8.2343e-02,\n",
            "         -8.7556e-02, -1.1854e-02, -9.0743e-02, -5.2962e-02, -1.8528e-02,\n",
            "          8.7295e-02, -7.9015e-02, -8.1107e-02, -1.4998e-01, -4.9176e-02,\n",
            "          7.6461e-02, -8.4499e-02,  1.8515e-04,  6.7784e-03, -1.0753e-01,\n",
            "          1.2935e-01, -1.7930e-02, -4.0069e-02, -6.4662e-03,  8.8335e-02,\n",
            "         -1.6080e-01,  5.7602e-02,  7.8606e-02,  1.2163e-01, -4.6123e-02],\n",
            "        [ 8.8452e-02, -5.1950e-02, -6.1485e-02, -1.1083e-02,  1.7234e-01,\n",
            "          1.5260e-01,  2.9206e-02, -4.8661e-02, -6.4836e-02,  1.6283e-01,\n",
            "         -1.6221e-01, -1.6758e-01, -9.7427e-02,  1.3490e-01, -1.3541e-01,\n",
            "          7.6884e-02, -1.2417e-01,  9.3733e-02,  1.7001e-02, -8.7776e-02,\n",
            "          2.2006e-02,  1.1535e-01, -5.7082e-02, -1.1580e-01,  1.4823e-02,\n",
            "          1.4355e-01, -1.2779e-01, -6.0269e-02, -1.4901e-01, -3.7032e-02]],\n",
            "       requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_parameters = sum(p.numel() for p in model.parameters() if p.requires_grad == True)\n",
        "\n",
        "print(num_parameters)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KDK8_tuFGKJd",
        "outputId": "5d6bb313-d2dd-426b-bcf4-39505019c94a"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2393\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "  output = torch.softmax(model(X), dim=1)\n",
        "\n",
        "print(output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yaw4d07XGRqx",
        "outputId": "5fe88892-b9ea-4069-c84f-3f28339bd5e3"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.4577, 0.2982, 0.2441]])\n"
          ]
        }
      ]
    }
  ]
}